{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m This environment is externally managed\n",
      "\u001b[31m╰─>\u001b[0m To install Python packages system-wide, try apt install\n",
      "\u001b[31m   \u001b[0m python3-xyz, where xyz is the package you are trying to\n",
      "\u001b[31m   \u001b[0m install.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Debian-packaged Python package,\n",
      "\u001b[31m   \u001b[0m create a virtual environment using python3 -m venv path/to/venv.\n",
      "\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip. Make\n",
      "\u001b[31m   \u001b[0m sure you have python3-full installed.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Debian packaged Python application,\n",
      "\u001b[31m   \u001b[0m it may be easiest to use pipx install xyz, which will manage a\n",
      "\u001b[31m   \u001b[0m virtual environment for you. Make sure you have pipx installed.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m See /usr/share/doc/python3.12/README.venv for more information.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
      "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# import nltk\n",
    "# from nltk.tokenize import PunktSentenceTokenizer\n",
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk #Natural Language Toolkit: A comprehensive library for text processing and analysis.\n",
    "# nltk.download(\"punkt\") #downloads the Punkt sentence tokenizer from NLTK's resources. This tokenizer is essential for splitting text into sentences,\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_text = \"This is an example text with multiple sentences. Here is another sentence. This one ends with a question mark?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = PunktSentenceTokenizer() #model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is an example text with multiple sentences.',\n",
       " 'Here is another sentence.',\n",
       " 'This one ends with a question mark?']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = tokenizer.tokenize(my_text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an example text with multiple sentences.\n",
      "Here is another sentence.\n",
      "This one ends with a question mark?\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "  print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "\n",
      " Brutal footage shows Samuel Eto'o attacking man at World Cup [Twitter]  Cameroon soccer federation president and former star player Samuel Eto'o apologized for kicking a man to the ground in what he called a \"violent altercation\" outside a World Cup stadium early Tuesday.  Eto'o had paused to pose for photos with fans near Stadium 974 after Brazil beat South Korea 4-1. Footage circulating on social media showed him then reacting to comments by a man holding a camera.  The former Barcelona and Inter Milan forward was initially held back by people in his entourage, but he then got clear and appeared to aim a kick at the man, who fell backwards to the ground.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"I had a violent altercation with a person who was probably an Algerian supporter,\" Eto'o wrote in statements posted in French and English on his Twitter account, citing a months-long campaign by that country's fans against Cameroon since their World Cup playoff in March.\n",
      " Follow The Standard\n",
      "                                    channel\n",
      "                                    on WhatsApp\n",
      "\n",
      "  \"I would like to apologize for losing my temper and reacting in a way that does not match my personality,\" said Eto'o, who has represented Qatar's World Cup organizing committee as a Global Legacy Ambassador since 2019. The man, Algerian social media personality Said Mamouni, later published a video on YouTube saying he was the person who was attacked, and that he was at a Qatari police station to file a complaint against Eto'o. \"Samuel had a fight with me. He hit me, and the one accompanying him pushed me. I'm here to lodge a complaint and he also smashed my camera,\" Mamouni said.\n",
      "        \n",
      "\n",
      "He said that Eto'o became violent after Mamouni asked him whether he had bribed Gambian referee Bakary Gassama in a controversial World Cup qualifying game between Cameroon and Algeria. Cameroon won the second leg 2-1 in the final moments of the match and qualified for the World Cup on the away goals rule.  Algeria's soccer federation filed a complaint with FIFA, soccer's governing body, demanding a replay of the match because of what it deemed were referring errors made by Gassama. FIFA dismissed the complaint.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "But Algeria's grievance also carried over to the Cameroon team's first official news conference in Qatar, one day before playing Switzerland. An Algerian reporter's question to Cameroon coach Rigobert Song about having \"bought qualification\" wasn't answered.    Samuel Eto'o attacking a man following Brazil's 4-1 win over South Korea at the Qatar World Cup [Twitter]  Eto'o has been in Qatar as head of the delegation from Cameroon, which was eliminated in the group stage last week. \"I have been the target of insults and allegations of cheating without any evidence,\" he wrote Tuesday. \"I pledge to continue to resist the relentless provocation and daily harassment of some Algerian supporters.\"  Eto'o is part of the FIFA Legends program that uses former players to promote soccer and it was unclear in what capacity Eto'o attended the game Monday night.  Qatari organizers of the World Cup said Eto'o hadn't been their guest at the game.\n",
      " \n",
      "\n",
      "\n",
      "  \n",
      "FIFA didn't immediately respond to a request for comment. A spokesman for the Cameroon federation didn't immediately answer phone calls or respond to messages seeking comment.  Qatar's government did not immediately respond to questions about the incident.  Stay informed. Subscribe to our newsletter \n",
      "By clicking on the SIGN UP button,  you agree to our Terms & Conditions and the Privacy Policy\n",
      "\n",
      "\n",
      "\n",
      "SIGN UP\n",
      " Eto'o played at four World Cups for Cameroon between 1998 and 2014, and was elected to lead its soccer federation one year ago.Stay Informed, Stay Empowered: Download the Standard ePaper App!\n",
      "He called on Algerian soccer officials \"to put an end to this unhealthy climate before a more serious tragedy occurs.\"  \"To Fennecs' fans,\" he said, noting the Algeria team's nickname, \"I wish that they find peace and manage to overcome the disappointment of a painful defeat, now behind us.\"\n",
      "                        \t\t\t\t\t\t\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# NLP works with unstructured data\n",
    "# Get some data from twitter/facebook, blogs, news\n",
    "import requests # allows you to send HTTP requests(get,post,put,delete) in Python, which is useful for interacting with web APIs or webscrapping\n",
    "from bs4 import BeautifulSoup #bs4 a Python library for pulling data out of HTML and XML files. Beautiful Soup is a library that makes it easy to scrape information from web pages\n",
    "URL = \"https://www.standardmedia.co.ke/sports/football/article/2001462653/samuel-etoo-sorry-after-attacking-a-man-following-brazils-4-1-win-over-south-korea-at-world-cup\"\n",
    "page = requests.get(URL) #using get method  to downloads the content of the webpage and stores it in the page variable\n",
    "soup = BeautifulSoup(page.content, \"html.parser\") #parses the downloaded HTML content using the html.parser. This creates a BeautifulSoup object called soup which represents the webpage structure.\n",
    "div = soup.findAll(\"div\", class_ = \"story\") #searches for all the <div> elements within the webpage that have a class attribute equal to \"story\"\n",
    "soup = BeautifulSoup(str(div)) #creates a new BeautifulSoup object from the string representation of the first element found in div. This step might be unnecessary if you only want the text from the entire section.\n",
    "text = soup.get_text() # extracts all the text content from within the new soup variable\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading pukt: Package 'pukt' not found in index\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/home/user/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sent_tokenize, word_tokenize\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# You imported both sent_tokenize and word_tokenize. While word_tokenize splits text into individual words, sent_tokenize splits text into sentences.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m tokenized_sent \u001b[38;5;241m=\u001b[39m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m tokenized_sent\n\u001b[1;32m      6\u001b[0m tokenized_text \u001b[38;5;241m=\u001b[39m word_tokenize(text)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/nltk/tokenize/__init__.py:106\u001b[0m, in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizers/punkt/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlanguage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pickle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/nltk/data.py:750\u001b[0m, in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<<Loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    749\u001b[0m \u001b[38;5;66;03m# Load the resource.\u001b[39;00m\n\u001b[0;32m--> 750\u001b[0m opened_resource \u001b[38;5;241m=\u001b[39m \u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m     resource_val \u001b[38;5;241m=\u001b[39m opened_resource\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/nltk/data.py:876\u001b[0m, in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    873\u001b[0m protocol, path_ \u001b[38;5;241m=\u001b[39m split_resource_url(resource_url)\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnltk\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mopen()\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;66;03m# urllib might not use mode='rb', so handle this one ourselves:\u001b[39;00m\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find(path_, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mopen()\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/home/user/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"pukt\") \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# You imported both sent_tokenize and word_tokenize. While word_tokenize splits text into individual words, sent_tokenize splits text into sentences.\n",
    "tokenized_sent = sent_tokenize(text)\n",
    "tokenized_sent\n",
    "tokenized_text = word_tokenize(text)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ve', \"haven't\", 'having', 'if', 'both', 'shan', 'couldn', 'ours', \"hasn't\", 'up', 'being', 's', 'he', 'above', 'below', 'other', 'but', 'same', 'only', 'mustn', 'wouldn', 'about', 'won', \"weren't\", 'are', 'because', 'on', 'did', \"needn't\", 'too', 'yours', 'in', 'we', 'your', 'don', 'such', 'now', \"hadn't\", 'a', 'me', 'to', \"you've\", \"won't\", 'ourselves', 'doing', 'this', 'hadn', 'is', 'have', 'over', 'until', \"that'll\", 'myself', 'y', \"shouldn't\", 'from', 'when', 'between', \"wasn't\", \"you'd\", 'isn', 'them', 'these', \"mightn't\", 'an', 'some', 'am', 'off', \"doesn't\", 'needn', 'or', 'at', 'while', 'all', 'here', \"wouldn't\", 'as', 'was', \"didn't\", 'again', 'should', \"couldn't\", 'no', 'for', 'will', 'they', 'him', 'those', 'haven', 'just', 'theirs', 'been', 'against', 'each', 'themselves', 'doesn', 'weren', 'during', 'my', 'her', 'has', 'its', 'after', 'and', 'didn', 'd', 'shouldn', 'itself', 'out', 'before', 'herself', 'what', 'own', \"shan't\", \"isn't\", 'were', 'himself', 'had', 're', 'few', 'you', 'which', 'hasn', 'wasn', 'his', 'once', 'their', \"don't\", 'the', 'there', 'yourself', 'how', 'why', 'mightn', \"she's\", \"it's\", \"mustn't\", 'do', 'ain', \"aren't\", 't', 'hers', 'any', \"should've\", 'with', 'by', 'down', 'under', 'through', 'then', 'ma', 'can', 'who', 'most', 'very', 'more', 'that', 'm', 'does', 'nor', 'our', 'yourselves', 'aren', 'whom', \"you're\", 'i', 'of', 'into', 'where', 'so', 'be', 'o', 'further', 'not', \"you'll\", 'it', 'than', 'she', 'll'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sarah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nltk.download(\"stopwords\") # Stopwords are commonly used words (like \"the\", \"a\", \"an\") that might not be very informative for analysis.\n",
    "from nltk.corpus import stopwords #imports the stopwords module from NLTK's corpus collection.\n",
    "print(stopwords.fileids()) # displays a list of identifiers for the available stopword sets in different languages\n",
    "# Get english stopwords\n",
    "mystopwords = set(stopwords.words('english')) # creates a set containing the English stopwords from the downloaded corpus.\n",
    "print(mystopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Words  ['[', 'Brutal', 'footage', 'shows', 'Samuel', 'Eto', \"'\", 'o', 'attacking', 'man', 'at', 'World', 'Cup', '[', 'Twitter', ']', 'Cameroon', 'soccer', 'federation', 'president', 'and', 'former', 'star', 'player', 'Samuel', 'Eto', \"'\", 'o', 'apologized', 'for', 'kicking', 'a', 'man', 'to', 'the', 'ground', 'in', 'what', 'he', 'called', 'a', '``', 'violent', 'altercation', \"''\", 'outside', 'a', 'World', 'Cup', 'stadium', 'early', 'Tuesday', '.', 'Eto', \"'\", 'o', 'had', 'paused', 'to', 'pose', 'for', 'photos', 'with', 'fans', 'near', 'Stadium', '974', 'after', 'Brazil', 'beat', 'South', 'Korea', '4-1', '.', 'Footage', 'circulating', 'on', 'social', 'media', 'showed', 'him', 'then', 'reacting', 'to', 'comments', 'by', 'a', 'man', 'holding', 'a', 'camera', '.', 'The', 'former', 'Barcelona', 'and', 'Inter', 'Milan', 'forward', 'was', 'initially', 'held', 'back', 'by', 'people', 'in', 'his', 'entourage', ',', 'but', 'he', 'then', 'got', 'clear', 'and', 'appeared', 'to', 'aim', 'a', 'kick', 'at', 'the', 'man', ',', 'who', 'fell', 'backwards', 'to', 'the', 'ground', '.', '``', 'I', 'had', 'a', 'violent', 'altercation', 'with', 'a', 'person', 'who', 'was', 'probably', 'an', 'Algerian', 'supporter', ',', \"''\", 'Eto', \"'\", 'o', 'wrote', 'in', 'statements', 'posted', 'in', 'French', 'and', 'English', 'on', 'his', 'Twitter', 'account', ',', 'citing', 'a', 'months-long', 'campaign', 'by', 'that', 'country', \"'s\", 'fans', 'against', 'Cameroon', 'since', 'their', 'World', 'Cup', 'playoff', 'in', 'March', '.', '``', 'I', 'would', 'like', 'to', 'apologize', 'for', 'losing', 'my', 'temper', 'and', 'reacting', 'in', 'a', 'way', 'that', 'does', 'not', 'match', 'my', 'personality', ',', \"''\", 'said', 'Eto', \"'\", 'o', ',', 'who', 'has', 'represented', 'Qatar', \"'s\", 'World', 'Cup', 'organizing', 'committee', 'as', 'a', 'Global', 'Legacy', 'Ambassador', 'since', '2019.', '.', 'Keep', 'Reading', 'COP29', ':', 'Why', 'Azerbaijan', 'is', 'seeking', 'partnerships', 'with', 'countries', 'with', 'limited', 'connections', 'and', 'partnerships', 'vivo', 'V30', '5G', 'launching', 'in', 'Kenya', ':', 'Step', 'into', 'the', 'future', 'with', 'style', 'How', 'Kenya', \"'s\", 'ICT', 'Accessibility', 'Standards', 'can', 'create', 'more', 'inclusive', 'workplaces', 'Unlocking', 'photographic', 'brilliance', ':', 'Vivo', 'V29', '5G', 'series', 'with', 'its', 'smart', 'aura', 'light', 'portrait', 'Vivo', 'introduces', 'V29', '5G', 'in', 'Kenya', 'with', 'innovative', 'smart', 'aura', 'light', 'portrait', 'and', 'stunning', '120', 'Hz', '3D', 'curved', 'screen', 'The', 'man', ',', 'Algerian', 'social', 'media', 'personality', 'Said', 'Mamouni', ',', 'later', 'published', 'a', 'video', 'on', 'YouTube', 'saying', 'he', 'was', 'the', 'person', 'who', 'was', 'attacked', ',', 'and', 'that', 'he', 'was', 'at', 'a', 'Qatari', 'police', 'station', 'to', 'file', 'a', 'complaint', 'against', 'Eto', \"'\", 'o', '.', '``', 'Samuel', 'had', 'a', 'fight', 'with', 'me', '.', 'He', 'hit', 'me', ',', 'and', 'the', 'one', 'accompanying', 'him', 'pushed', 'me', '.', 'I', \"'m\", 'here', 'to', 'lodge', 'a', 'complaint', 'and', 'he', 'also', 'smashed', 'my', 'camera', ',', \"''\", 'Mamouni', 'said', '.', 'He', 'said', 'that', 'Eto', \"'\", 'o', 'became', 'violent', 'after', 'Mamouni', 'asked', 'him', 'whether', 'he', 'had', 'bribed', 'Gambian', 'referee', 'Bakary', 'Gassama', 'in', 'a', 'controversial', 'World', 'Cup', 'qualifying', 'game', 'between', 'Cameroon', 'and', 'Algeria', '.', 'Cameroon', 'won', 'the', 'second', 'leg', '2-1', 'in', 'the', 'final', 'moments', 'of', 'the', 'match', 'and', 'qualified', 'for', 'the', 'World', 'Cup', 'on', 'the', 'away', 'goals', 'rule', '.', 'Algeria', \"'s\", 'soccer', 'federation', 'filed', 'a', 'complaint', 'with', 'FIFA', ',', 'soccer', \"'s\", 'governing', 'body', ',', 'demanding', 'a', 'replay', 'of', 'the', 'match', 'because', 'of', 'what', 'it', 'deemed', 'were', 'referring', 'errors', 'made', 'by', 'Gassama', '.', 'FIFA', 'dismissed', 'the', 'complaint', '.', 'But', 'Algeria', \"'s\", 'grievance', 'also', 'carried', 'over', 'to', 'the', 'Cameroon', 'team', \"'s\", 'first', 'official', 'news', 'conference', 'in', 'Qatar', ',', 'one', 'day', 'before', 'playing', 'Switzerland', '.', 'An', 'Algerian', 'reporter', \"'s\", 'question', 'to', 'Cameroon', 'coach', 'Rigobert', 'Song', 'about', 'having', '``', 'bought', 'qualification', \"''\", 'was', \"n't\", 'answered', '.', 'Samuel', 'Eto', \"'\", 'o', 'attacking', 'a', 'man', 'following', 'Brazil', \"'s\", '4-1', 'win', 'over', 'South', 'Korea', 'at', 'the', 'Qatar', 'World', 'Cup', '[', 'Twitter', ']', 'Eto', \"'\", 'o', 'has', 'been', 'in', 'Qatar', 'as', 'head', 'of', 'the', 'delegation', 'from', 'Cameroon', ',', 'which', 'was', 'eliminated', 'in', 'the', 'group', 'stage', 'last', 'week', '.', '``', 'I', 'have', 'been', 'the', 'target', 'of', 'insults', 'and', 'allegations', 'of', 'cheating', 'without', 'any', 'evidence', ',', \"''\", 'he', 'wrote', 'Tuesday', '.', '``', 'I', 'pledge', 'to', 'continue', 'to', 'resist', 'the', 'relentless', 'provocation', 'and', 'daily', 'harassment', 'of', 'some', 'Algerian', 'supporters', '.', \"''\", 'Eto', \"'\", 'o', 'is', 'part', 'of', 'the', 'FIFA', 'Legends', 'program', 'that', 'uses', 'former', 'players', 'to', 'promote', 'soccer', 'and', 'it', 'was', 'unclear', 'in', 'what', 'capacity', 'Eto', \"'\", 'o', 'attended', 'the', 'game', 'Monday', 'night', '.', 'Qatari', 'organizers', 'of', 'the', 'World', 'Cup', 'said', 'Eto', \"'\", 'o', 'had', \"n't\", 'been', 'their', 'guest', 'at', 'the', 'game', '.', 'FIFA', 'did', \"n't\", 'immediately', 'respond', 'to', 'a', 'request', 'for', 'comment', '.', 'A', 'spokesman', 'for', 'the', 'Cameroon', 'federation', 'did', \"n't\", 'immediately', 'answer', 'phone', 'calls', 'or', 'respond', 'to', 'messages', 'seeking', 'comment', '.', 'Qatar', \"'s\", 'government', 'did', 'not', 'immediately', 'respond', 'to', 'questions', 'about', 'the', 'incident', '.', 'Eto', \"'\", 'o', 'played', 'at', 'four', 'World', 'Cups', 'for', 'Cameroon', 'between', '1998', 'and', '2014', ',', 'and', 'was', 'elected', 'to', 'lead', 'its', 'soccer', 'federation', 'one', 'year', 'ago', '.', 'He', 'called', 'on', 'Algerian', 'soccer', 'officials', '``', 'to', 'put', 'an', 'end', 'to', 'this', 'unhealthy', 'climate', 'before', 'a', 'more', 'serious', 'tragedy', 'occurs', '.', \"''\", '``', 'To', 'Fennecs', \"'\", 'fans', ',', \"''\", 'he', 'said', ',', 'noting', 'the', 'Algeria', 'team', \"'s\", 'nickname', ',', '``', 'I', 'wish', 'that', 'they', 'find', 'peace', 'and', 'manage', 'to', 'overcome', 'the', 'disappointment', 'of', 'a', 'painful', 'defeat', ',', 'now', 'behind', 'us', '.', \"''\", ']']\n",
      "New Words  ['[', 'Brutal', 'footage', 'shows', 'Samuel', 'Eto', \"'\", 'attacking', 'man', 'World', 'Cup', '[', 'Twitter', ']', 'Cameroon', 'soccer', 'federation', 'president', 'former', 'star', 'player', 'Samuel', 'Eto', \"'\", 'apologized', 'kicking', 'man', 'ground', 'called', '``', 'violent', 'altercation', \"''\", 'outside', 'World', 'Cup', 'stadium', 'early', 'Tuesday', '.', 'Eto', \"'\", 'paused', 'pose', 'photos', 'fans', 'near', 'Stadium', '974', 'Brazil', 'beat', 'South', 'Korea', '4-1', '.', 'Footage', 'circulating', 'social', 'media', 'showed', 'reacting', 'comments', 'man', 'holding', 'camera', '.', 'former', 'Barcelona', 'Inter', 'Milan', 'forward', 'initially', 'held', 'back', 'people', 'entourage', ',', 'got', 'clear', 'appeared', 'aim', 'kick', 'man', ',', 'fell', 'backwards', 'ground', '.', '``', 'violent', 'altercation', 'person', 'probably', 'Algerian', 'supporter', ',', \"''\", 'Eto', \"'\", 'wrote', 'statements', 'posted', 'French', 'English', 'Twitter', 'account', ',', 'citing', 'months-long', 'campaign', 'country', \"'s\", 'fans', 'Cameroon', 'since', 'World', 'Cup', 'playoff', 'March', '.', '``', 'would', 'like', 'apologize', 'losing', 'temper', 'reacting', 'way', 'match', 'personality', ',', \"''\", 'said', 'Eto', \"'\", ',', 'represented', 'Qatar', \"'s\", 'World', 'Cup', 'organizing', 'committee', 'Global', 'Legacy', 'Ambassador', 'since', '2019.', '.', 'Keep', 'Reading', 'COP29', ':', 'Azerbaijan', 'seeking', 'partnerships', 'countries', 'limited', 'connections', 'partnerships', 'vivo', 'V30', '5G', 'launching', 'Kenya', ':', 'Step', 'future', 'style', 'Kenya', \"'s\", 'ICT', 'Accessibility', 'Standards', 'create', 'inclusive', 'workplaces', 'Unlocking', 'photographic', 'brilliance', ':', 'Vivo', 'V29', '5G', 'series', 'smart', 'aura', 'light', 'portrait', 'Vivo', 'introduces', 'V29', '5G', 'Kenya', 'innovative', 'smart', 'aura', 'light', 'portrait', 'stunning', '120', 'Hz', '3D', 'curved', 'screen', 'man', ',', 'Algerian', 'social', 'media', 'personality', 'Said', 'Mamouni', ',', 'later', 'published', 'video', 'YouTube', 'saying', 'person', 'attacked', ',', 'Qatari', 'police', 'station', 'file', 'complaint', 'Eto', \"'\", '.', '``', 'Samuel', 'fight', '.', 'hit', ',', 'one', 'accompanying', 'pushed', '.', \"'m\", 'lodge', 'complaint', 'also', 'smashed', 'camera', ',', \"''\", 'Mamouni', 'said', '.', 'said', 'Eto', \"'\", 'became', 'violent', 'Mamouni', 'asked', 'whether', 'bribed', 'Gambian', 'referee', 'Bakary', 'Gassama', 'controversial', 'World', 'Cup', 'qualifying', 'game', 'Cameroon', 'Algeria', '.', 'Cameroon', 'second', 'leg', '2-1', 'final', 'moments', 'match', 'qualified', 'World', 'Cup', 'away', 'goals', 'rule', '.', 'Algeria', \"'s\", 'soccer', 'federation', 'filed', 'complaint', 'FIFA', ',', 'soccer', \"'s\", 'governing', 'body', ',', 'demanding', 'replay', 'match', 'deemed', 'referring', 'errors', 'made', 'Gassama', '.', 'FIFA', 'dismissed', 'complaint', '.', 'Algeria', \"'s\", 'grievance', 'also', 'carried', 'Cameroon', 'team', \"'s\", 'first', 'official', 'news', 'conference', 'Qatar', ',', 'one', 'day', 'playing', 'Switzerland', '.', 'Algerian', 'reporter', \"'s\", 'question', 'Cameroon', 'coach', 'Rigobert', 'Song', '``', 'bought', 'qualification', \"''\", \"n't\", 'answered', '.', 'Samuel', 'Eto', \"'\", 'attacking', 'man', 'following', 'Brazil', \"'s\", '4-1', 'win', 'South', 'Korea', 'Qatar', 'World', 'Cup', '[', 'Twitter', ']', 'Eto', \"'\", 'Qatar', 'head', 'delegation', 'Cameroon', ',', 'eliminated', 'group', 'stage', 'last', 'week', '.', '``', 'target', 'insults', 'allegations', 'cheating', 'without', 'evidence', ',', \"''\", 'wrote', 'Tuesday', '.', '``', 'pledge', 'continue', 'resist', 'relentless', 'provocation', 'daily', 'harassment', 'Algerian', 'supporters', '.', \"''\", 'Eto', \"'\", 'part', 'FIFA', 'Legends', 'program', 'uses', 'former', 'players', 'promote', 'soccer', 'unclear', 'capacity', 'Eto', \"'\", 'attended', 'game', 'Monday', 'night', '.', 'Qatari', 'organizers', 'World', 'Cup', 'said', 'Eto', \"'\", \"n't\", 'guest', 'game', '.', 'FIFA', \"n't\", 'immediately', 'respond', 'request', 'comment', '.', 'spokesman', 'Cameroon', 'federation', \"n't\", 'immediately', 'answer', 'phone', 'calls', 'respond', 'messages', 'seeking', 'comment', '.', 'Qatar', \"'s\", 'government', 'immediately', 'respond', 'questions', 'incident', '.', 'Eto', \"'\", 'played', 'four', 'World', 'Cups', 'Cameroon', '1998', '2014', ',', 'elected', 'lead', 'soccer', 'federation', 'one', 'year', 'ago', '.', 'called', 'Algerian', 'soccer', 'officials', '``', 'put', 'end', 'unhealthy', 'climate', 'serious', 'tragedy', 'occurs', '.', \"''\", '``', 'Fennecs', \"'\", 'fans', ',', \"''\", 'said', ',', 'noting', 'Algeria', 'team', \"'s\", 'nickname', ',', '``', 'wish', 'find', 'peace', 'manage', 'overcome', 'disappointment', 'painful', 'defeat', ',', 'behind', 'us', '.', \"''\", ']']\n"
     ]
    }
   ],
   "source": [
    "# # Assuming you have your text stored in a variable called 'text'\n",
    "filtered_words =[]\n",
    "for word in tokenized_text: # Split text into words\n",
    "       if word.lower() not in mystopwords:  # Check if word is not a stopword\n",
    "               filtered_words.append(word) #to appent is to put\n",
    "\n",
    "print(\"Old Words \", tokenized_text)\n",
    "print(\"New Words \", filtered_words) \n",
    "\n",
    "# print(filtered_text)  # This will print the text without stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brutal',\n",
       " 'footage',\n",
       " 'shows',\n",
       " 'Samuel',\n",
       " 'Eto',\n",
       " 'attacking',\n",
       " 'man',\n",
       " 'World',\n",
       " 'Cup',\n",
       " 'Twitter',\n",
       " 'Cameroon',\n",
       " 'soccer',\n",
       " 'federation',\n",
       " 'president',\n",
       " 'former',\n",
       " 'star',\n",
       " 'player',\n",
       " 'Samuel',\n",
       " 'Eto',\n",
       " 'apologized',\n",
       " 'kicking',\n",
       " 'man',\n",
       " 'ground',\n",
       " 'called',\n",
       " 'violent',\n",
       " 'altercation',\n",
       " 'outside',\n",
       " 'World',\n",
       " 'Cup',\n",
       " 'stadium',\n",
       " 'early',\n",
       " 'Tuesday',\n",
       " 'Eto',\n",
       " 'paused',\n",
       " 'pose',\n",
       " 'photos',\n",
       " 'fans',\n",
       " 'near',\n",
       " 'Stadium',\n",
       " 'Brazil',\n",
       " 'beat',\n",
       " 'South',\n",
       " 'Korea',\n",
       " 'Footage',\n",
       " 'circulating',\n",
       " 'social',\n",
       " 'media',\n",
       " 'showed',\n",
       " 'reacting',\n",
       " 'comments',\n",
       " 'man',\n",
       " 'holding',\n",
       " 'camera',\n",
       " 'former',\n",
       " 'Barcelona',\n",
       " 'Inter',\n",
       " 'Milan',\n",
       " 'forward',\n",
       " 'initially',\n",
       " 'held',\n",
       " 'back',\n",
       " 'people',\n",
       " 'entourage',\n",
       " 'got',\n",
       " 'clear',\n",
       " 'appeared',\n",
       " 'aim',\n",
       " 'kick',\n",
       " 'man',\n",
       " 'fell',\n",
       " 'backwards',\n",
       " 'ground',\n",
       " 'violent',\n",
       " 'altercation',\n",
       " 'person',\n",
       " 'probably',\n",
       " 'Algerian',\n",
       " 'supporter',\n",
       " 'Eto',\n",
       " 'wrote',\n",
       " 'statements',\n",
       " 'posted',\n",
       " 'French',\n",
       " 'English',\n",
       " 'Twitter',\n",
       " 'account',\n",
       " 'citing',\n",
       " 'campaign',\n",
       " 'country',\n",
       " 'fans',\n",
       " 'Cameroon',\n",
       " 'since',\n",
       " 'World',\n",
       " 'Cup',\n",
       " 'playoff',\n",
       " 'March',\n",
       " 'would',\n",
       " 'like',\n",
       " 'apologize',\n",
       " 'losing',\n",
       " 'temper',\n",
       " 'reacting',\n",
       " 'way',\n",
       " 'match',\n",
       " 'personality',\n",
       " 'said',\n",
       " 'Eto',\n",
       " 'represented',\n",
       " 'Qatar',\n",
       " 'World',\n",
       " 'Cup',\n",
       " 'organizing',\n",
       " 'committee',\n",
       " 'Global',\n",
       " 'Legacy',\n",
       " 'Ambassador',\n",
       " 'since',\n",
       " 'Keep',\n",
       " 'Reading',\n",
       " 'Azerbaijan',\n",
       " 'seeking',\n",
       " 'partnerships',\n",
       " 'countries',\n",
       " 'limited',\n",
       " 'connections',\n",
       " 'partnerships',\n",
       " 'vivo',\n",
       " 'launching',\n",
       " 'Kenya',\n",
       " 'Step',\n",
       " 'future',\n",
       " 'style',\n",
       " 'Kenya',\n",
       " 'ICT',\n",
       " 'Accessibility',\n",
       " 'Standards',\n",
       " 'create',\n",
       " 'inclusive',\n",
       " 'workplaces',\n",
       " 'Unlocking',\n",
       " 'photographic',\n",
       " 'brilliance',\n",
       " 'Vivo',\n",
       " 'series',\n",
       " 'smart',\n",
       " 'aura',\n",
       " 'light',\n",
       " 'portrait',\n",
       " 'Vivo',\n",
       " 'introduces',\n",
       " 'Kenya',\n",
       " 'innovative',\n",
       " 'smart',\n",
       " 'aura',\n",
       " 'light',\n",
       " 'portrait',\n",
       " 'stunning',\n",
       " 'Hz',\n",
       " 'curved',\n",
       " 'screen',\n",
       " 'man',\n",
       " 'Algerian',\n",
       " 'social',\n",
       " 'media',\n",
       " 'personality',\n",
       " 'Said',\n",
       " 'Mamouni',\n",
       " 'later',\n",
       " 'published',\n",
       " 'video',\n",
       " 'YouTube',\n",
       " 'saying',\n",
       " 'person',\n",
       " 'attacked',\n",
       " 'Qatari',\n",
       " 'police',\n",
       " 'station',\n",
       " 'file',\n",
       " 'complaint',\n",
       " 'Eto',\n",
       " 'Samuel',\n",
       " 'fight',\n",
       " 'hit',\n",
       " 'one',\n",
       " 'accompanying',\n",
       " 'pushed',\n",
       " 'lodge',\n",
       " 'complaint',\n",
       " 'also',\n",
       " 'smashed',\n",
       " 'camera',\n",
       " 'Mamouni',\n",
       " 'said',\n",
       " 'said',\n",
       " 'Eto',\n",
       " 'became',\n",
       " 'violent',\n",
       " 'Mamouni',\n",
       " 'asked',\n",
       " 'whether',\n",
       " 'bribed',\n",
       " 'Gambian',\n",
       " 'referee',\n",
       " 'Bakary',\n",
       " 'Gassama',\n",
       " 'controversial',\n",
       " 'World',\n",
       " 'Cup',\n",
       " 'qualifying',\n",
       " 'game',\n",
       " 'Cameroon',\n",
       " 'Algeria',\n",
       " 'Cameroon',\n",
       " 'second',\n",
       " 'leg',\n",
       " 'final',\n",
       " 'moments',\n",
       " 'match',\n",
       " 'qualified',\n",
       " 'World',\n",
       " 'Cup',\n",
       " 'away',\n",
       " 'goals',\n",
       " 'rule',\n",
       " 'Algeria',\n",
       " 'soccer',\n",
       " 'federation',\n",
       " 'filed',\n",
       " 'complaint',\n",
       " 'FIFA',\n",
       " 'soccer',\n",
       " 'governing',\n",
       " 'body',\n",
       " 'demanding',\n",
       " 'replay',\n",
       " 'match',\n",
       " 'deemed',\n",
       " 'referring',\n",
       " 'errors',\n",
       " 'made',\n",
       " 'Gassama',\n",
       " 'FIFA',\n",
       " 'dismissed',\n",
       " 'complaint',\n",
       " 'Algeria',\n",
       " 'grievance',\n",
       " 'also',\n",
       " 'carried',\n",
       " 'Cameroon',\n",
       " 'team',\n",
       " 'first',\n",
       " 'official',\n",
       " 'news',\n",
       " 'conference',\n",
       " 'Qatar',\n",
       " 'one',\n",
       " 'day',\n",
       " 'playing',\n",
       " 'Switzerland',\n",
       " 'Algerian',\n",
       " 'reporter',\n",
       " 'question',\n",
       " 'Cameroon',\n",
       " 'coach',\n",
       " 'Rigobert',\n",
       " 'Song',\n",
       " 'bought',\n",
       " 'qualification',\n",
       " 'answered',\n",
       " 'Samuel',\n",
       " 'Eto',\n",
       " 'attacking',\n",
       " 'man',\n",
       " 'following',\n",
       " 'Brazil',\n",
       " 'win',\n",
       " 'South',\n",
       " 'Korea',\n",
       " 'Qatar',\n",
       " 'World',\n",
       " 'Cup',\n",
       " 'Twitter',\n",
       " 'Eto',\n",
       " 'Qatar',\n",
       " 'head',\n",
       " 'delegation',\n",
       " 'Cameroon',\n",
       " 'eliminated',\n",
       " 'group',\n",
       " 'stage',\n",
       " 'last',\n",
       " 'week',\n",
       " 'target',\n",
       " 'insults',\n",
       " 'allegations',\n",
       " 'cheating',\n",
       " 'without',\n",
       " 'evidence',\n",
       " 'wrote',\n",
       " 'Tuesday',\n",
       " 'pledge',\n",
       " 'continue',\n",
       " 'resist',\n",
       " 'relentless',\n",
       " 'provocation',\n",
       " 'daily',\n",
       " 'harassment',\n",
       " 'Algerian',\n",
       " 'supporters',\n",
       " 'Eto',\n",
       " 'part',\n",
       " 'FIFA',\n",
       " 'Legends',\n",
       " 'program',\n",
       " 'uses',\n",
       " 'former',\n",
       " 'players',\n",
       " 'promote',\n",
       " 'soccer',\n",
       " 'unclear',\n",
       " 'capacity',\n",
       " 'Eto',\n",
       " 'attended',\n",
       " 'game',\n",
       " 'Monday',\n",
       " 'night',\n",
       " 'Qatari',\n",
       " 'organizers',\n",
       " 'World',\n",
       " 'Cup',\n",
       " 'said',\n",
       " 'Eto',\n",
       " 'guest',\n",
       " 'game',\n",
       " 'FIFA',\n",
       " 'immediately',\n",
       " 'respond',\n",
       " 'request',\n",
       " 'comment',\n",
       " 'spokesman',\n",
       " 'Cameroon',\n",
       " 'federation',\n",
       " 'immediately',\n",
       " 'answer',\n",
       " 'phone',\n",
       " 'calls',\n",
       " 'respond',\n",
       " 'messages',\n",
       " 'seeking',\n",
       " 'comment',\n",
       " 'Qatar',\n",
       " 'government',\n",
       " 'immediately',\n",
       " 'respond',\n",
       " 'questions',\n",
       " 'incident',\n",
       " 'Eto',\n",
       " 'played',\n",
       " 'four',\n",
       " 'World',\n",
       " 'Cups',\n",
       " 'Cameroon',\n",
       " 'elected',\n",
       " 'lead',\n",
       " 'soccer',\n",
       " 'federation',\n",
       " 'one',\n",
       " 'year',\n",
       " 'ago',\n",
       " 'called',\n",
       " 'Algerian',\n",
       " 'soccer',\n",
       " 'officials',\n",
       " 'put',\n",
       " 'end',\n",
       " 'unhealthy',\n",
       " 'climate',\n",
       " 'serious',\n",
       " 'tragedy',\n",
       " 'occurs',\n",
       " 'Fennecs',\n",
       " 'fans',\n",
       " 'said',\n",
       " 'noting',\n",
       " 'Algeria',\n",
       " 'team',\n",
       " 'nickname',\n",
       " 'wish',\n",
       " 'find',\n",
       " 'peace',\n",
       " 'manage',\n",
       " 'overcome',\n",
       " 'disappointment',\n",
       " 'painful',\n",
       " 'defeat',\n",
       " 'behind',\n",
       " 'us']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove any words from filtered_text that contain non-alphabetic characters like punctuation marks, numbers, or symbols.\n",
    "clean_words = [word for word in filtered_words if word.isalpha()] # uses a list comprehension to iterate through each word in filtered_text and conditionally add it to a new list called clean_words.\n",
    "# The if statement checks if the current word (word) consists only of alphabetic characters using the isalpha() method. This method returns True if the word contains only letters and False otherwise.\n",
    "# for word in filtered_words:\n",
    "#     # print (word)\n",
    "#     if word.isalpha():\n",
    "#         clean_words = word\n",
    "#         print (clean_words)\n",
    "clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Eto', 13),\n",
       " ('World', 9),\n",
       " ('Cameroon', 9),\n",
       " ('Cup', 8),\n",
       " ('man', 6),\n",
       " ('soccer', 6),\n",
       " ('Algerian', 5),\n",
       " ('said', 5),\n",
       " ('Qatar', 5),\n",
       " ('Samuel', 4),\n",
       " ('federation', 4),\n",
       " ('complaint', 4),\n",
       " ('Algeria', 4),\n",
       " ('FIFA', 4),\n",
       " ('Twitter', 3),\n",
       " ('former', 3),\n",
       " ('violent', 3),\n",
       " ('fans', 3),\n",
       " ('match', 3),\n",
       " ('Kenya', 3),\n",
       " ('Mamouni', 3),\n",
       " ('one', 3),\n",
       " ('game', 3),\n",
       " ('immediately', 3),\n",
       " ('respond', 3),\n",
       " ('attacking', 2),\n",
       " ('ground', 2),\n",
       " ('called', 2),\n",
       " ('altercation', 2),\n",
       " ('Tuesday', 2)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyze the most frequent words in your cleaned text.  (probability and statistics)\n",
    "from nltk.probability import FreqDist\n",
    "frequency = FreqDist(clean_words)\n",
    "frequency.most_common(30) #This method returns a list containing the most frequent words. we've specified 30 here, so it will return the 30 most frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# justpaste.it/cq844\n",
    "#  generating a word cloud image based on the text\n",
    "from wordcloud import WordCloud, STOPWORDS  #This line imports the WordCloud class and the built-in stopwords list from the wordcloud library. WordCloud is used to generate the visual representation of words, and STOPWORDS provides a list of common words (like \"the\", \"a\", \"an\") that are often excluded from word clouds.\n",
    "\n",
    "from PIL import Image #This line imports the Image class from the Pillow Fork (PIL) library, which is commonly used for image processing in Python. This allows you to open and display the generated word cloud image.\n",
    "\n",
    "#Function to Create Wordcloud\n",
    "def create_wordcloud(text):\n",
    "        stopwords = set(STOPWORDS) #creates a set containing the stopwords from the imported STOPWORDS list\n",
    "        wc = WordCloud(background_color=\"white\", #Sets the background color of the word cloud to white.\n",
    "        max_words=3000, #Limits the number of words displayed in the word cloud to 3000 (you can adjust this value).\n",
    "        stopwords=stopwords,repeat=True) #Specifies the list of stopwords to exclude from the word cloud (uses the set you created earlier). repeat=True Allows words to appear multiple times in the word cloud, scaled by their frequency (optional)\n",
    "        wc.generate(str(text)) # This method analyzes the text and generates the word cloud image based on word frequencies.\n",
    "        wc.to_file(\"wc.png\") #to_file method saves the generated word cloud as a PNG image file named \"wc.png\"\n",
    "        print(\"Word Cloud Saved Successfully\") # This line prints a message indicating successful word cloud generation.\n",
    "        path=\"wc.png\" \n",
    "        display(Image.open(path))  #print the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TransposedFont' object has no attribute 'getbbox'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcreate_wordcloud\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfrequency\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmost_common\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 13\u001b[0m, in \u001b[0;36mcreate_wordcloud\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      9\u001b[0m stopwords \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(STOPWORDS) \u001b[38;5;66;03m#creates a set containing the stopwords from the imported STOPWORDS list\u001b[39;00m\n\u001b[0;32m     10\u001b[0m wc \u001b[38;5;241m=\u001b[39m WordCloud(background_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhite\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m#Sets the background color of the word cloud to white.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m max_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3000\u001b[39m, \u001b[38;5;66;03m#Limits the number of words displayed in the word cloud to 3000 (you can adjust this value).\u001b[39;00m\n\u001b[0;32m     12\u001b[0m stopwords\u001b[38;5;241m=\u001b[39mstopwords,repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m#Specifies the list of stopwords to exclude from the word cloud (uses the set you created earlier). repeat=True Allows words to appear multiple times in the word cloud, scaled by their frequency (optional)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mwc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# This method analyzes the text and generates the word cloud image based on word frequencies.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m wc\u001b[38;5;241m.\u001b[39mto_file(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwc.png\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m#to_file method saves the generated word cloud as a PNG image file named \"wc.png\"\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWord Cloud Saved Successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# This line prints a message indicating successful word cloud generation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Sarah\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wordcloud\\wordcloud.py:642\u001b[0m, in \u001b[0;36mWordCloud.generate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m    628\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[0;32m    629\u001b[0m \n\u001b[0;32m    630\u001b[0m \u001b[38;5;124;03m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;124;03m    self\u001b[39;00m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 642\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Sarah\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wordcloud\\wordcloud.py:624\u001b[0m, in \u001b[0;36mWordCloud.generate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[0;32m    608\u001b[0m \n\u001b[0;32m    609\u001b[0m \u001b[38;5;124;03mThe input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;124;03mself\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    623\u001b[0m words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_text(text)\n\u001b[1;32m--> 624\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_frequencies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Sarah\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wordcloud\\wordcloud.py:453\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    451\u001b[0m     font_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 453\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_frequencies\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfrequencies\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mmax_font_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;66;03m# find font sizes\u001b[39;00m\n\u001b[0;32m    456\u001b[0m     sizes \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout_]\n",
      "File \u001b[1;32mc:\\Users\\Sarah\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wordcloud\\wordcloud.py:511\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    508\u001b[0m transposed_font \u001b[38;5;241m=\u001b[39m ImageFont\u001b[38;5;241m.\u001b[39mTransposedFont(\n\u001b[0;32m    509\u001b[0m     font, orientation\u001b[38;5;241m=\u001b[39morientation)\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# get size of resulting text\u001b[39;00m\n\u001b[1;32m--> 511\u001b[0m box_size \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtextbbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfont\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransposed_font\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manchor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# find possible places using integral image:\u001b[39;00m\n\u001b[0;32m    513\u001b[0m result \u001b[38;5;241m=\u001b[39m occupancy\u001b[38;5;241m.\u001b[39msample_position(box_size[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmargin,\n\u001b[0;32m    514\u001b[0m                                    box_size[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmargin,\n\u001b[0;32m    515\u001b[0m                                    random_state)\n",
      "File \u001b[1;32mc:\\Users\\Sarah\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\PIL\\ImageDraw.py:567\u001b[0m, in \u001b[0;36mImageDraw.textbbox\u001b[1;34m(self, xy, text, font, anchor, spacing, align, direction, features, language, stroke_width, embedded_color)\u001b[0m\n\u001b[0;32m    565\u001b[0m     font \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetfont()\n\u001b[0;32m    566\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGBA\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m embedded_color \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfontmode\n\u001b[1;32m--> 567\u001b[0m bbox \u001b[38;5;241m=\u001b[39m \u001b[43mfont\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetbbox\u001b[49m(\n\u001b[0;32m    568\u001b[0m     text, mode, direction, features, language, stroke_width, anchor\n\u001b[0;32m    569\u001b[0m )\n\u001b[0;32m    570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bbox[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m xy[\u001b[38;5;241m0\u001b[39m], bbox[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m xy[\u001b[38;5;241m1\u001b[39m], bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m xy[\u001b[38;5;241m0\u001b[39m], bbox[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m+\u001b[39m xy[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TransposedFont' object has no attribute 'getbbox'"
     ]
    }
   ],
   "source": [
    "create_wordcloud(frequency.most_common(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def get_top_n_gram(corpus,ngram_range,n=None):\n",
    "  vec = CountVectorizer(ngram_range=ngram_range,stop_words = 'english').fit(corpus)\n",
    "  bag_of_words = vec.transform(corpus)\n",
    "  sum_words = bag_of_words.sum(axis=0)\n",
    "  words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "  words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "  return words_freq[:n]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
